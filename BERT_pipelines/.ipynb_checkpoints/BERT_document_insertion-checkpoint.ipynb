{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328c746-3c52-4bea-8d50-2cec1da3cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "from openai import OpenAI, Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320c907c-a078-4a4b-acc2-275502735b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeed3389-2f23-4e69-b597-08e8380fcf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>reduced_content_p=0.1</th>\n",
       "      <th>reduced_content_p=0.3</th>\n",
       "      <th>reduced_content_p=0.5</th>\n",
       "      <th>reduced_content_p=0.7</th>\n",
       "      <th>reduced_content_p=0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/greek-gaming-gr...</td>\n",
       "      <td>Wed, Nov 20, 2024, 8:52 AM</td>\n",
       "      <td>(Reuters) - Greece's biggest gaming company O...</td>\n",
       "      <td>(Reuters) - Greece's biggest gaming company O...</td>\n",
       "      <td>(Reuters) Greece's biggest gaming company sai...</td>\n",
       "      <td>company Wednesday its revenue increased quart...</td>\n",
       "      <td>company OPAP on revenue increased 17.6% the th...</td>\n",
       "      <td>its the helped activity. gaming revenue was th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/applovin-plans-...</td>\n",
       "      <td>Wed, Nov 20, 2024, 9:52 AM</td>\n",
       "      <td>(Bloomberg) -- AppLovin Corp. is making its d...</td>\n",
       "      <td>(Bloomberg) -- AppLovin Corp. is making its d...</td>\n",
       "      <td>(Bloomberg) -- Corp. making its debut in US in...</td>\n",
       "      <td>(Bloomberg) -- AppLovin is making investment-g...</td>\n",
       "      <td>Corp. making debut the bond being Most Read Tr...</td>\n",
       "      <td>Corp. is market Spaces York’s Public Here’s It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/gildan-nears-de...</td>\n",
       "      <td>Wed, Nov 20, 2024, 7:56 AM</td>\n",
       "      <td>(Bloomberg) -- Gildan Activewear Inc. is cons...</td>\n",
       "      <td>(Bloomberg) -- Gildan is considering selling ...</td>\n",
       "      <td>(Bloomberg) Activewear Inc. is selling its fir...</td>\n",
       "      <td>(Bloomberg) -- Gildan is as soon Wednesday, ac...</td>\n",
       "      <td>is considering selling its as people Most Park...</td>\n",
       "      <td>(Bloomberg) considering Seismic York’s $9 Toky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/qualcomm-expect...</td>\n",
       "      <td>Tue, Nov 19, 2024, 2:25 PM</td>\n",
       "      <td>(Bloomberg) -- Qualcomm Inc., the world’s big...</td>\n",
       "      <td>(Bloomberg) -- Qualcomm Inc., the world’s big...</td>\n",
       "      <td>(Bloomberg) Qualcomm Inc., world’s biggest sm...</td>\n",
       "      <td>(Bloomberg) -- Qualcomm Inc., biggest of proc...</td>\n",
       "      <td>Qualcomm into billion in annual fiscal 2029. ...</td>\n",
       "      <td>markets additional York’s Agency Could Tokyo’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>https://finance.yahoo.com/news/openai-releases...</td>\n",
       "      <td>Wed, Nov 20, 2024, 8:40 AM</td>\n",
       "      <td>OpenAI envisions teachers using its AI-powere...</td>\n",
       "      <td>OpenAI teachers using its to create plans and...</td>\n",
       "      <td>OpenAI envisions teachers using AI-powered to...</td>\n",
       "      <td>OpenAI envisions using its AI-powered tools p...</td>\n",
       "      <td>envisions teachers tools interactive for But s...</td>\n",
       "      <td>students. some potential OpenAI a online help ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          title                                                url  \\\n",
       "0   0  Yahoo Finance  https://finance.yahoo.com/news/greek-gaming-gr...   \n",
       "1   1  Yahoo Finance  https://finance.yahoo.com/news/applovin-plans-...   \n",
       "2   2  Yahoo Finance  https://finance.yahoo.com/news/gildan-nears-de...   \n",
       "3   3  Yahoo Finance  https://finance.yahoo.com/news/qualcomm-expect...   \n",
       "4   4  Yahoo Finance  https://finance.yahoo.com/news/openai-releases...   \n",
       "\n",
       "                         date  \\\n",
       "0  Wed, Nov 20, 2024, 8:52 AM   \n",
       "1  Wed, Nov 20, 2024, 9:52 AM   \n",
       "2  Wed, Nov 20, 2024, 7:56 AM   \n",
       "3  Tue, Nov 19, 2024, 2:25 PM   \n",
       "4  Wed, Nov 20, 2024, 8:40 AM   \n",
       "\n",
       "                                             content  \\\n",
       "0   (Reuters) - Greece's biggest gaming company O...   \n",
       "1   (Bloomberg) -- AppLovin Corp. is making its d...   \n",
       "2   (Bloomberg) -- Gildan Activewear Inc. is cons...   \n",
       "3   (Bloomberg) -- Qualcomm Inc., the world’s big...   \n",
       "4   OpenAI envisions teachers using its AI-powere...   \n",
       "\n",
       "                               reduced_content_p=0.1  \\\n",
       "0   (Reuters) - Greece's biggest gaming company O...   \n",
       "1   (Bloomberg) -- AppLovin Corp. is making its d...   \n",
       "2   (Bloomberg) -- Gildan is considering selling ...   \n",
       "3   (Bloomberg) -- Qualcomm Inc., the world’s big...   \n",
       "4   OpenAI teachers using its to create plans and...   \n",
       "\n",
       "                               reduced_content_p=0.3  \\\n",
       "0   (Reuters) Greece's biggest gaming company sai...   \n",
       "1  (Bloomberg) -- Corp. making its debut in US in...   \n",
       "2  (Bloomberg) Activewear Inc. is selling its fir...   \n",
       "3   (Bloomberg) Qualcomm Inc., world’s biggest sm...   \n",
       "4   OpenAI envisions teachers using AI-powered to...   \n",
       "\n",
       "                               reduced_content_p=0.5  \\\n",
       "0   company Wednesday its revenue increased quart...   \n",
       "1  (Bloomberg) -- AppLovin is making investment-g...   \n",
       "2  (Bloomberg) -- Gildan is as soon Wednesday, ac...   \n",
       "3   (Bloomberg) -- Qualcomm Inc., biggest of proc...   \n",
       "4   OpenAI envisions using its AI-powered tools p...   \n",
       "\n",
       "                               reduced_content_p=0.7  \\\n",
       "0  company OPAP on revenue increased 17.6% the th...   \n",
       "1  Corp. making debut the bond being Most Read Tr...   \n",
       "2  is considering selling its as people Most Park...   \n",
       "3   Qualcomm into billion in annual fiscal 2029. ...   \n",
       "4  envisions teachers tools interactive for But s...   \n",
       "\n",
       "                               reduced_content_p=0.9  \n",
       "0  its the helped activity. gaming revenue was th...  \n",
       "1  Corp. is market Spaces York’s Public Here’s It...  \n",
       "2  (Bloomberg) considering Seismic York’s $9 Toky...  \n",
       "3  markets additional York’s Agency Could Tokyo’s...  \n",
       "4  students. some potential OpenAI a online help ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../word-dropout/11_20_26_27_Articles_DROPOUT.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a081ea-0530-497e-92e3-d1e6e3f6b1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6584c3e-552e-43a3-9d95-b81aec160c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np \\n\\n# Step 1: Load GloVe vectors from the 100-dimensional txt file\\ndef load_glove_model(glove_file=\\'./glove.6B.100d.txt\\'):\\n    glove_model = {}\\n    with open(glove_file, \\'r\\', encoding=\"utf-8\") as f:\\n        for line in f:\\n            split_line = line.split()\\n            word = split_line[0]\\n            embedding = np.array([float(val) for val in split_line[1:]])\\n            glove_model[word] = embedding\\n    print(f\"Loaded {len(glove_model)} words into the GloVe model.\")\\n    return glove_model\\n\\n# Load the GloVe 100D file\\nglove_model = load_glove_model(\"glove.6B.100d.txt\")  # Make sure this path is correct\\n\\n# Step 2: Convert sentences (documents) to vectors\\ndef sentence_to_glove(sentence, model, embedding_dim=100):\\n    words = sentence.split()\\n    embeddings = [model[word] for word in words if word in model]\\n    if embeddings:\\n        return np.mean(embeddings, axis=0)  # Average word vectors\\n    else:\\n        return np.zeros(embedding_dim)  # Return a zero vector if no words match\\n\\n\\ninsertions = []\\nindex = 0\\nfor s in df[\"text\"]:\\n    insertions.append({\"id\": index, \"embedding\": sentence_to_glove(s, glove_model), \"sentence\": s})\\n    index = index+1\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Glove embeddings\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np \n",
    "\n",
    "# Step 1: Load GloVe vectors from the 100-dimensional txt file\n",
    "def load_glove_model(glove_file='./glove.6B.100d.txt'):\n",
    "    glove_model = {}\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"Loaded {len(glove_model)} words into the GloVe model.\")\n",
    "    return glove_model\n",
    "\n",
    "# Load the GloVe 100D file\n",
    "glove_model = load_glove_model(\"glove.6B.100d.txt\")  # Make sure this path is correct\n",
    "\n",
    "# Step 2: Convert sentences (documents) to vectors\n",
    "def sentence_to_glove(sentence, model, embedding_dim=100):\n",
    "    words = sentence.split()\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  # Average word vectors\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)  # Return a zero vector if no words match\n",
    "\n",
    "\n",
    "insertions = []\n",
    "index = 0\n",
    "for s in df[\"text\"]:\n",
    "    insertions.append({\"id\": index, \"embedding\": sentence_to_glove(s, glove_model), \"sentence\": s})\n",
    "    index = index+1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59498bb-6e46-4eba-aeb8-d1917eca6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_embeddings_from_openai(text):\\n    response = openai_client.embeddings.create(\\n        input=text,\\n        model=\"text-embedding-ada-002\"\\n    )\\n    return response.data[0].embedding\\n\\ninsertions = []\\nindex = 0\\nfor s in df[\"text\"]:\\n    insertions.append({\"id\": index, \"embedding\": get_embeddings_from_openai(s), \"sentence\": s})\\n    index = index+1\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OpenAI's Ada-002 Embeddings\n",
    "\n",
    "\"\"\"\n",
    "def get_embeddings_from_openai(text):\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "insertions = []\n",
    "index = 0\n",
    "for s in df[\"text\"]:\n",
    "    insertions.append({\"id\": index, \"embedding\": get_embeddings_from_openai(s), \"sentence\": s})\n",
    "    index = index+1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a658ca6-ef37-4b20-82c9-99b2276f9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [0, 0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "\n",
    "    collection_name = f\"yahoo_finance_article_DROPOUT_{int(p * 100)}\"\n",
    "\n",
    "    milvus_client.drop_collection(\n",
    "        collection_name=collection_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1642d6b-d2b0-49ef-a104-437718c26d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': <LoadState: Loaded>}\n",
      "{'state': <LoadState: Loaded>}\n",
      "{'state': <LoadState: Loaded>}\n",
      "{'state': <LoadState: Loaded>}\n",
      "{'state': <LoadState: Loaded>}\n",
      "{'state': <LoadState: Loaded>}\n"
     ]
    }
   ],
   "source": [
    "for p in [0, 0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "\n",
    "    collection_name = f\"yahoo_finance_article_DROPOUT_{int(p * 100)}\"\n",
    "    \n",
    "    schema = MilvusClient.create_schema(\n",
    "        auto_id=False,\n",
    "        enable_dynamic_field=True,\n",
    "    )\n",
    "    \n",
    "    schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n",
    "    schema.add_field(field_name=\"embedded_document\", datatype=DataType.FLOAT_VECTOR, dim=384) # 100 dimensional GloVe vectors\n",
    "    \n",
    "    # dimensions: \n",
    "    # 100 for GloVe-100\n",
    "    # 1536 dimensions for ada-002\n",
    "    # 384 for all-MiniLM-L6-v2\n",
    "    \n",
    "    index_params = milvus_client.prepare_index_params()\n",
    "    \n",
    "    index_params.add_index(\n",
    "        field_name=\"id\",\n",
    "        index_type=\"STL_SORT\"\n",
    "    )\n",
    "    \n",
    "    index_params.add_index(\n",
    "        field_name=\"embedded_document\", \n",
    "        index_type=\"IVF_FLAT\",\n",
    "        metric_type=\"IP\",\n",
    "        params={ \"nlist\": 128 }\n",
    "    )\n",
    "    \n",
    "    milvus_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        schema=schema,\n",
    "        index_params=index_params\n",
    "    )\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    res = milvus_client.get_load_state(\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    \n",
    "    print(res)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "916feb43-25e8-408f-8549-db75049b7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BERT Embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "def get_embeddings_from_bert(sentence):\n",
    "    return model.encode([sentence])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ea78f6c-da2e-48ec-8105-84b54d396509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting insertion of documents for p = 0\n",
      "Average number of tokens in p=0 collection: 652.5235849056604\n",
      "Insertion finished. Execution took 27.599462509155273 seconds.\n",
      "Starting insertion of documents for p = 0.1\n",
      "Average number of tokens in p=0.1 collection: 587.7547169811321\n",
      "Insertion finished. Execution took 31.73040223121643 seconds.\n",
      "Starting insertion of documents for p = 0.3\n",
      "Average number of tokens in p=0.3 collection: 457.22641509433964\n",
      "Insertion finished. Execution took 33.29304504394531 seconds.\n",
      "Starting insertion of documents for p = 0.5\n",
      "Average number of tokens in p=0.5 collection: 326.54245283018867\n",
      "Insertion finished. Execution took 31.57529902458191 seconds.\n",
      "Starting insertion of documents for p = 0.7\n",
      "Average number of tokens in p=0.7 collection: 196.23584905660377\n",
      "Insertion finished. Execution took 22.61218285560608 seconds.\n",
      "Starting insertion of documents for p = 0.9\n",
      "Average number of tokens in p=0.9 collection: 65.68867924528301\n",
      "Insertion finished. Execution took 13.550365447998047 seconds.\n"
     ]
    }
   ],
   "source": [
    "insertion_times = {}\n",
    "\n",
    "for p in [0, 0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "\n",
    "    print(f\"Starting insertion of documents for p = {p}\")\n",
    "    \n",
    "    collection_name = f\"yahoo_finance_article_DROPOUT_{int(p * 100)}\"\n",
    "    content_column_name = \"content\" if p == 0 else f\"reduced_content_p={p}\"\n",
    "\n",
    "    avg_number_of_tokens = np.mean(df[content_column_name].map(lambda x: len(x.split(\" \"))).to_list())\n",
    "\n",
    "    print(f\"Average number of tokens in p={p} collection: {avg_number_of_tokens}\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    insertions = df.apply(lambda x: {\"id\": x[\"id\"], \"embedded_document\": get_embeddings_from_bert(x[content_column_name])}, axis=1).to_list()\n",
    "\n",
    "    res = milvus_client.insert(\n",
    "        collection_name=collection_name,\n",
    "        data=insertions\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    exec_time = end - start\n",
    "    insertion_times[str(p)] = exec_time\n",
    "\n",
    "    print(f\"Insertion finished. Execution took {exec_time} seconds.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ae315-49fd-4382-8752-87f3d3d6b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
